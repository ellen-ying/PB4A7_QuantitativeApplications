---
output:
  pdf_document:
    number_sections: true
    keep_tex: true
    latex_engine: xelatex
mainfont: Times New Roman
geometry: margin=1.0in
fontsize: 11pt
bibliography: reference.bib
csl: apa.csl
header-includes:
  - \newcommand{\bcenter}{\begin{center}}
  - \newcommand{\ecenter}{\end{center}}
  - \newcommand{\btitlepage}{\begin{titlepage}}
  - \newcommand{\etitlepage}{\end{titlepage}}
  - \usepackage{setspace}\onehalfspacing
  - \usepackage{booktabs}
  - \usepackage[font=small,labelfont=bf]{caption}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse); library(knitr);library(kableExtra)

calculate_mean <- function(alpha, beta, beta_sq, white, male, acc, aged, mean_age){
  return(alpha + beta*(-0.001) + beta_sq*(-0.001)^2 +
           (white + male + acc)*0.5 + aged*mean_age)
}
```

\btitlepage

\bcenter

\vspace*{30mm}

Candidate number: 49045

\vspace*{5mm}

# Replication of Hansen (2015) Punishment and Deterrence: Evidence from Drunk Driving {-}

\vspace*{30mm}

Submitted as the summative assessment for \

PB4A7: Quantitative Applications for Behavioural Science 2022

\ecenter

\etitlepage

\newpage

In the study *Punishment and Deterrence: Evidence from Drunk Driving* [@hansen_punishment_2015], Hansen investigated the effect of punishments and sanctions on reducing repeat drunk driving. The study implemented a quasi-experimental design, utilising the administrative records from 1995 to 2011 of the state of Washington, U.S., where two thresholds of blood alcohol content (BAC) are used to determine the status of driving under the influence (DUI). Specifically, a driver with a measured BAC over 0.08 is considered a case of DUI and will be punished via measures such as fines, jail time, and driving license suspension. One with a BAC over 0.15 is considered a case of aggravated DUI, to which more severe punishments and sanctions are applied. Since BAC measure has clear-cut numeric thresholds for determining whether a driver will receive harsher punishments, and neither drivers or police can manipulate this measure, Hansen applied a regression discontinuity design to analyse the data **(expand on the justification of using RDD)**. He hypothesized that receiving harsher punishments and sanctions at both thresholds would reduce offenders' future recidivism of DUI. He further applied the RDD to analyse the effect of receiving harsher punishments on the degree of deterrence, incapacitation, and rehabilitation in order to identify the mechanism through which harsher punishments might reduce recidivism **(check the paper to see whether this sentence is precise)**.

**Ideally also the results**

The present study aims to replicate the findings from @hansen_punishment_2015 using regression discontinuity design applied to a similar data **(what is it exactly...)**. It will be focused on estimating the effect of receiving punishments on reducing recidivism at the 0.08 BAC threshold only. The paper proceeds as follows. Section 1 discusses the econometric method and assumptions underlying its application to the current data. Section 2 presents the main results, and Section 3 discusses critiques and extensions to the original study. Section 4 concludes.


# Methods and Assumptions

## Assumptions of the regression discontinuity design

The present study applies the regression discontinuity design to the data provided by the class instructor. Several assumptions need to be met so that the regression discontinuity design can give accurate estimates. First, people need to be randomly assigned to receiving punishment at the BAC threshold. In other words, neither the drivers nor the police can manipulate the BAC level and thus whether one will receive punishment. Hansen (2015) has already given a plausible theoretical justification for this assumption. Empirically, I plot the distribution of BAC and test for discontinuity in its distribution at the threshold. Figure \ref{fig:bac_hist_continuous} shows the distribution of BAC level. Based on a recently developed local polynomial density estimator [@cattaneo_simple_2020], the hypothesis that the distribution is continuous at 0.08 cannot be rejected at the level of 0.05 (*p* = 0.890). Therefore, there is no evidence for the existence of manipulation on the BAC level.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\columnwidth]{../figures/bac_histogram_continuous.pdf}
  \caption{\textbf{Histogram of blood alcohol content as a continuous variable.} The blood alcohol content is plotted as a continuous variable with a bin width of 0.001, the precision used on the breathalysers. The y-axis represents the frequency of observations in each bin. The vertical black lines represent the two thresholds at 0.08 and 0.15.}
  \label{fig:bac_hist_continuous}
\end{figure}

The second assumption is that the running variable should not contain non-random heaping, which can lead to biased estimates in regression discontinuity models [@barreca_heaping-induced_2016]. In other words, BAC should not be much more likely to take certain values than others. Based on Figure \ref{fig:bac_hist_continuous}, this assumption seems to be violated. Curiously, when BAC is plotted as a discrete variable, non-random heaping disappears (Figure \ref{fig:bac_hist_discrete}). A closer inspection of the data suggests that this is probably due to the lack of precision in BAC in the current data. Many BAC values deviate by a very small amount from the values that are supposed to be given by the breathalysers (i.e., precise to three digits after the decimal point). Some bins have a value at the left boundary deviating upwards and a value at the right boundary deviating downwards. Such bins will contain a larger number of observations than other bins and thus leads to heaping. This would not occur if the data records the values precisely so that the number of observations are rightly separated into and plotted by two bins, or if we treat BAC as discrete and give each value its own bin. **(consider using a simulation to justify this claim?)**

\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\columnwidth]{../figures/bac_histogram_discrete.pdf}
  \caption{\textbf{Histogram of blood alcohol content as a discrete variable.} The blood alcohol content is plotted as a discrete variable with a bin width of 0.001, the precision used on the breathalysers. The y-axis represents the frequency of observations in each bin. The vertical black lines represent the two thresholds at 0.08 and 0.15.}
  \label{fig:bac_hist_discrete}
\end{figure}


## The model

The present study utilises a local linear regression model with a rectangular kernel weight function to estimate the effect of receiving punishments at the threshold on recidivism. For sensitivity analyses, the models are re-estimated using second-order polynomials and triangle kernel function). The model is specified by the following function:

\begin{equation}
  \label{eqn:model}
  R_i = \alpha + \beta_1 DUI_i + \beta_2 BAC_i + \beta_3 DUI_i \times BAC_i + \tau Z_i + \epsilon_i
\end{equation}

where the variable $DUI_i$ is an indicator of whether BAC is above the 0.08 threshold, $BAC_i$ is the measure of BAC level, $R_i$ is an indicator of recidivism, and $Z_i$ is a vector of control variables. The variable $BAC_i$ in the model is centered around the threshold value of 0.08 so that the coefficients directly reflect the estimates of the effect.

## Inclusion of control variables

In order to determine whether any covariates should be included in the model, I run preliminary analyses on the effect of receiving punishments at the threshold on four predetermined characteristics, including three demographic variables (gender, race, and age) and the BAC test being conducted in a traffic accident. The analyses use the same local linear regression model specified in equation (\ref{eqn:model}), with a bandwidth of 0.05 and no kernel weight function. As Table \ref{tab:covariate} shows, I fail to reject any of the null hypotheses that predetermined characteristics remained the same at the threshold. This indicates that gender, race, age, and the BAC test being conducted in a traffic accident, on average, were not different between people who did not receive punishments and those who received punishments at the threshold \footnote{This is an additional evidence for the absence of manipulation at the threshold, which further assures the regression discontinuity design can deliver unbiased estimates.}. According to [@calonico_regression_2019], I will include the four predetermined characteristics in regression discontinuity models to improve the estimation precision of the effects of receiving punishments at the threshold on recidivism.

```{r covariate, include = FALSE, echo=FALSE}
# estimates of covriate
# means are calculated using the formula alpha + beta_2*(-0.001)
tibble(
  rowname = c("DUI", " ", "Mean", "Numb. of Obs."),
  male = c("0.006", "(0.006)", "0.784", "89,967"),
  white = c("0.006", "(0.005)", "0.846", "89,967"),
  age = c("–0.141", "(0.164)", "0.085", "89,967"),
  accident = c("–0.003", "(0.004)", "33.99", "89,967"),
) %>%
  column_to_rownames("rowname") %>%
  kable(
    digits = 2, format = "latex", booktabs = TRUE,
    caption = "Regression Discontinuity Estimates of the Effect of Receiving Punishments at the Threshold on Predetermined Characteristics",
    row.names = TRUE, col.names = c("Male", "White", "Age", "Accident"),
    align = "ccccc") %>%
  column_spec(2:5, width = "5em") %>%
  footnote(
    general = "\\\\textit{Note.} Regression discontinuity based estimates of the effect of receiving punishments at the threshold on four predetermined characteristics. All models use a bandwidth of 0.05 and a universal kernel weight function. Counterfactual predictions of mean recidivism are calculated at the 0.079 BAC threshold. Heteroscedasticity-robust standard errors are in parentheses. $^{*}\\\\, p<0.1$, $^{**}\\\\, p<0.05$, $^{***}\\\\, p<0.01$.",
    general_title = "", escape = FALSE,
    threeparttable = TRUE, fixed_small_size = TRUE) #%>%
 # kable_styling(latex_options = "scale_down")
```

\begingroup
\renewcommand{\arraystretch}{1.3}

\begin{table}

\caption{Regression Discontinuity Estimates of the Effect of Receiving Punishments at the 0.08 BAC Threshold on Predetermined Characteristics}
\label{tab:covariate}
\centering
\begin{threeparttable}
\begin{tabular}[t]{l>{\centering\arraybackslash}p{5em}>{\centering\arraybackslash}p{5em}>{\centering\arraybackslash}p{5em}>{\centering\arraybackslash}p{5em}}
\toprule
  & Male & White & Age & Accident\\
\midrule
\textit{DUI} & 0.006 & 0.006 & –0.141 & –0.003\\
 & (0.006) & (0.005) & (0.164) & (0.004)\\
Mean & 0.784 & 0.846 & 0.085 & 33.99\\
Num. of Obs. & 89,967 & 89,967 & 89,967 & 89,967\\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Note.} Regression discontinuity based estimates of the effect of receiving punishments at the 0.08 BAC threshold on four predetermined characteristics. All models use a bandwidth of 0.05 and a rectangular kernel weight function. Counterfactual predictions of mean recidivism is calculated at the 0.079 BAC threshold. Heteroscedasticity-robust standard errors are in parentheses. $^{*}\, p<0.1$, $^{**}\, p<0.05$, $^{***}\, p<0.01$.
\end{tablenotes}
\end{threeparttable}
\end{table}

\endgroup


# Results

## The Effect of Punishments on Recidivism

Table \ref{tab:main} reports the estimated effect of receiving punishments at the threshold on recidivism. Local linear regression model with a rectangular kernel  function gives the estimate that receiving punishments at the 0.08 BAC threshold decreases recidivism by 2.4 percentage points, which is statistically significant at the level of 0.01. Local second-order polynomial with a rectangular kernel  function gives an estimate of a decrease in recidivism by 1.4 percentage points, which is statistically significant at the level of 0.05. These estimates are consistent across both bandwidths and across models with different types of kernel functions.

```{r mian, include=FALSE, echo=FALSE}
# estimates from main analyses and sensitivity analyses
# means are calculate using the formula alpha + beta_2*(-0.001) + beta_3*(-0.001)^2 + tau*Z_0
# where Z_0 is a vector of the mean of control variables
tibble(
  rowname = c("DUI", " ", "Mean", "Controls", "Num. of Obs.",
              "a", "b", "c", "d", "e"),
  rect.linear = c("–0.024***", "(0.004)", "0.104", "Yes", "89,967",
                  "–0.021***", "(0.006)", "0.101", "Yes", "46,957"),
  rect.qua = c("–0.014**", "(0.006)", "0.099", "Yes", "89,967",
               "–0.014*", "(0.008)", "0.098", "Yes", "46,957"),
  tri.linear = c("–0.020***", "(0.005)", "0.100", "Yes", "89,967",
                  "–0.018***", "(0.006)", "0.101", "Yes", "46,957"),
  tri.qua = c("–0.014**", "(0.006)", "0.099", "Yes", "89,967",
              "–0.016*", "(0.009)", "0.100", "Yes", "46,957"),
) %>%
  column_to_rownames("rowname") %>%
  kable(
    digits = 2, format = "latex", booktabs = TRUE,
    caption = "Regression Discontinuity Estimates of the Effect of Receiving Punishments at the 0.08 BAC Threshold on Recidivism",
    row.names = TRUE, col.names = rep(c("Linear", "Quadratic"), 2),
    align = "ccccc") %>%
  column_spec(2:5, width = "8em") %>%
  add_header_above(
    c(" " = 1, "Rectangular kernel" = 2, "Triangular kernel" = 2)
  ) %>%
  footnote(
    general = "\\\\textit{Note.} Regression discontinuity based estimates of the effect of receiving punishments at the 0.08 BAC threshold on recidivism. The upper panel presents estimates based on a 0.05 bandwidth, and the lower panel presents estimates based on a 0.025 bandwidth. The table includes results from both linear and quadratic models, with either a rectangular or a triangular kernel weight function. Controls include individuals' gender, race, age, and an indicator of whether the BAC test was conducted in a traffic accident. Counterfactual predictions of mean recidivism are calculated at the 0.079 BAC threshold and mean age of the respective populations, averaging over individuals' gender and race, as well as over whether the BAC testing was conducted in an accident. Heteroscedasticity-robust standard errors are in parentheses. $^{*}\\\\, p<0.1$, $^{**}\\\\, p<0.05$, $^{***}\\\\, p<0.01$.",
    general_title = "", escape = FALSE,
    threeparttable = TRUE, fixed_small_size = TRUE)
```

\begingroup
\renewcommand{\arraystretch}{1.1}

\begin{table}

\caption{Regression Discontinuity Estimates of the Effect of Receiving Punishments at the 0.08 BAC Threshold on Recidivism}
\label{tab:main}
\centering
\begin{threeparttable}
\begin{tabular}[t]{l>{\centering\arraybackslash}p{8em}>{\centering\arraybackslash}p{8em}>{\centering\arraybackslash}p{8em}>{\centering\arraybackslash}p{8em}}
\toprule
\multicolumn{1}{c}{ } & \multicolumn{2}{c}{Rectangular kernel} & \multicolumn{2}{c}{Triangular kernel} \\
\cmidrule(l{3pt}r{3pt}){2-3} \cmidrule(l{3pt}r{3pt}){4-5}
  & Linear & Quadratic & Linear & Quadratic\\
\midrule
\multicolumn{5}{l}{\textit{A. DUI $\in$ [0.03, 0.13]}} \\
\textit{DUI} & –0.024*** & –0.014** & –0.020*** & –0.014**\\
 & (0.004) & (0.006) & (0.005) & (0.006)\\
Mean & 0.104 & 0.099 & 0.100 & 0.099\\
Controls & Yes & Yes & Yes & Yes\\
Num. of Obs. & 89,967 & 89,967 & 89,967 & 89,967\\
\addlinespace
\multicolumn{5}{l}{\textit{B. DUI $\in$ [0.055, 0.105]}} \\
\textit{DUI} & –0.021*** & –0.014* & –0.018*** & –0.016*\\
 & (0.006) & (0.008) & (0.006) & (0.009)\\
Mean & 0.101 & 0.098 & 0.101 & 0.100\\
Controls & Yes & Yes & Yes & Yes\\
Num. of Obs. & 46,957 & 46,957 & 46,957 & 46,957\\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Note.} Regression discontinuity based estimates of the effect of receiving punishments at the 0.08 BAC threshold on recidivism. Panel A presents estimates based on a 0.05 bandwidth, and Panel B presents estimates based on a 0.025 bandwidth. The table includes results from both linear and quadratic models, with either a rectangular or a triangular kernel weight function. Controls include individuals' gender, race, age, and an indicator of whether the BAC test was conducted in a traffic accident. Counterfactual predictions of mean recidivism are calculated at the 0.079 BAC threshold and mean age of the respective populations, averaging over individuals' gender and race, as well as over whether the BAC testing was conducted in an accident. Heteroscedasticity-robust standard errors are in parentheses. $^{*}\, p<0.1$, $^{**}\, p<0.05$, $^{***}\, p<0.01$.
\end{tablenotes}
\end{threeparttable}
\end{table}

\endgroup

Figure \ref{fig:rdplot} plots means of recidivism in bins and predicted recidivism based on linear regression models or second-order polynomials using observations within the interval $BAC \in [0.06, 0.11]$. Panel A and B and Panel C and D use different methods for binning observations and representing confidence intervals to ensure the robustness of the visual evidence (See the figure caption). All panels show an apparent drop in recidivism at the BAC threshold of 0.08. This visually indicates that there is an effect of receiving punishments at the BAC threshold in decreasing recidivism.

\begin{figure}[H]
  \centering
  \includegraphics[width=1\columnwidth]{../figures/combined.pdf}
  \caption{\textbf{Regression Discontinuity Plot of the Effect of Receiving Punishments at the 0.08 BAC Threshold on Recidivism.} Plot of means of recidivism in bins and predicted recidivism using simple regression models. In plotting the binned means (gray points), Panel A and B choose the number of bins on each side of the threshold using the formula $min\{\sqrt{n}, 10 \times \frac{\ln{n}}{\ln{10}}\}$, while Panel C and D choose the number using quantile spaced binning **(Calonico et al., 2015)**. For the confidence intervals (shaded areas in red), Panel A and B plot the 95\% confidence interval of the regression models, while Panel C and D plot the 95\% confidence interval of each bin. For the regression models (red lines), Panel A and C plot the best fitted linear model, while Panel B and D plot the best fitted second-order polynomial. All panels plot the data within the interval $BAC \in [0.06, 0.11]$. The vertical dashed lines represent the BAC threshold at 0.08.}
  \label{fig:rdplot}
\end{figure}


## Robustness

Since there seems to be non-random heaping in the current data (Figure \ref{fig:bac_hist_continuous}), this section will use donut regression discontinuity models to investigate the robustness of the results presented in the last section. Donut regression discontinuity models entirely drop the observations near the threshold. Under appropriate assumptions, they are effective in preventing a heap just at the threshold from biasing the estimates  [@barreca_heaping-induced_2016].

For the present study, I drop the observations in the interval $BAC \in [0.079, 0.081]$, and re-estimate local linear and quadratic models with either a rectangular or a triangular kernel weight function. It is worth stressing that robustness test using local polynomials is especially important in a donut regression discontinuity design. This is because a donut regression model gets rid of the very observations on which the estimates of local average effects rely upon. The estimates given by donut regression models are essentially based on models' extrapolation over the region of the donut [@dowd_donuts_2021] and may be especially sensitive to the assumptions about the underlying functional form **(Consider justifying this using a simulation)**. Using polynomials with different orders can ensure the robustness of the results over different functional assumptions.

The results from donut regression discontinuity models are presented in Table \ref{tab:donut}. According to the local linear regression model with a rectangular kernel function, receiving punishments at the threshold decreases recidivism by 2.6 percentage points and is statistically significant at the level of 0.01. According to the local second-order polynomial with a rectangular kernel function, receiving punishments at the threshold decreases recidivism by 1.4 percentage points and is statistically significant at the level of 0.1. These estimates are consistent across both bandwidths and across models with different types of kernel functions, except for not being statistically significant in quadratic models estimated with narrower bandwidth of 0.025. Therefore, the results given by donut regression discontinuity models are essentially identical with those given by ordinary models presents in the last section.

```{r donut, include=FALSE, echo=FALSE}
# estimates from donut hole regression
# means are calculate using the formula alpha + beta_2*(-0.001) + beta_3*(-0.001)^2 + tau*Z_0
# where Z_0 is a vector of the mean of control variables
tibble(
  rowname = c("DUI", " ", "Mean", "Controls", "Num. of Obs.",
              "a", "b", "c", "d", "e"),
  rect.linear = c("–0.026***", "(0.005)", "0.105", "Yes", "88,085",
                  "–0.022***", "(0.007)", "0.103", "Yes", "45,075"),
  rect.qua = c("–0.014*", "(0.007)", "0.099", "Yes", "88,085",
               "–0.015", "(0.011)", "0.099", "Yes", "45,075"),
  tri.linear = c("–0.022***", "(0.005)", "0.102", "Yes", "88,085",
                  "–0.020***", "(0.007)", "0.103", "Yes", "45,075"),
  tri.qua = c("–0.018**", "(0.006)", "0.101", "Yes", "88,085",
              "–0.020", "(0.012)", "0.104", "Yes", "45,075"),
) %>%
  column_to_rownames("rowname") %>%
  kable(
    digits = 2, format = "latex", booktabs = TRUE,
    caption = "Donut Regression Discontinuity Estimates of the Effect of Receiving Punishments at the 0.08 BAC Threshold on Recidivism",
    row.names = TRUE, col.names = rep(c("Linear", "Quadratic"), 2),
    align = "ccccc") %>%
  column_spec(2:5, width = "8em") %>%
  add_header_above(
    c(" " = 1, "Rectangular kernel" = 2, "Triangular kernel" = 2)
  ) %>%
  footnote(
    general = "\\\\textit{Note.} Regression discontinuity based estimates of the effect of receiving punishments at the 0.08 BAC threshold on recidivism after dropping observations in the interval [0.079, 0.081]. The upper panel presents estimates based on a 0.05 bandwidth, and the lower panel presents estimates based on a 0.025 bandwidth. The table includes results from both linear and quadratic models, with either a rectangular or a triangular kernel weight function. Controls include individuals' gender, race, age, and an indicator of whether the BAC test was conducted in a traffic accident. Counterfactual predictions of mean recidivism are calculated at the 0.079 BAC threshold and mean age of the respective populations, averaging over individuals' gender and race, as well as over whether the BAC testing was conducted in an accident. Heteroscedasticity-robust standard errors are in parentheses. $^{*}\\\\, p<0.1$, $^{**}\\\\, p<0.05$, $^{***}\\\\, p<0.01$.",
    general_title = "", escape = FALSE,
    threeparttable = TRUE, fixed_small_size = TRUE)
```

\begingroup
\renewcommand{\arraystretch}{1.1}

\begin{table}

\caption{Donut Regression Discontinuity Estimates of the Effect of Receiving Punishments at the 0.08 BAC Threshold on Recidivism}
\label{tab:donut}
\centering
\begin{threeparttable}
\begin{tabular}[t]{l>{\centering\arraybackslash}p{8em}>{\centering\arraybackslash}p{8em}>{\centering\arraybackslash}p{8em}>{\centering\arraybackslash}p{8em}}
\toprule
\multicolumn{1}{c}{ } & \multicolumn{2}{c}{Rectangular kernel} & \multicolumn{2}{c}{Triangular kernel} \\
\cmidrule(l{3pt}r{3pt}){2-3} \cmidrule(l{3pt}r{3pt}){4-5}
  & Linear & Quadratic & Linear & Quadratic\\
\midrule
\multicolumn{5}{l}{\textit{A. DUI $\in$ [0.03, 0.13]}} \\
\textit{DUI} & –0.026*** & –0.014* & –0.022*** & –0.018**\\
 & (0.005) & (0.007) & (0.005) & (0.006)\\
Mean & 0.105 & 0.099 & 0.102 & 0.101\\
Controls & Yes & Yes & Yes & Yes\\
Num. of Obs. & 88,085 & 88,085 & 88,085 & 88,085\\
\addlinespace
\multicolumn{5}{l}{\textit{B. DUI $\in$ [0.055, 0.105]}} \\
\textit{DUI} & –0.022*** & –0.015 & –0.020*** & –0.020\\
 & (0.007) & (0.011) & (0.007) & (0.012)\\
Mean & 0.103 & 0.099 & 0.103 & 0.104\\
Controls & Yes & Yes & Yes & Yes\\
Num. of Obs. & 45,075 & 45,075 & 45,075 & 45,075\\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Note.} Regression discontinuity based estimates of the effect of receiving punishments at the 0.08 BAC threshold on recidivism after dropping observations in the interval [0.079, 0.081]. Panel A presents estimates based on a 0.05 bandwidth, and Panel B presents estimates based on a 0.025 bandwidth. The table includes results from both linear and quadratic models, with either a rectangular or a triangular kernel weight function. Controls include individuals' gender, race, age, and an indicator of whether the BAC test was conducted in a traffic accident. Counterfactual predictions of mean recidivism are calculated at the 0.079 BAC threshold and mean age of the respective populations, averaging over individuals' gender and race, as well as over whether the BAC testing was conducted in an accident. Heteroscedasticity-robust standard errors are in parentheses. $^{*}\, p<0.1$, $^{**}\, p<0.05$, $^{***}\, p<0.01$.
\end{tablenotes}
\end{threeparttable}
\end{table}

\endgroup


# Discussion, Critique and Extension

Using a regression discontinuity design, the present study aims to replicate the findings of Hansen (2015) about the effect of punishments and sanctions on reducing repeat drunk driving. Specifically, the present study focuses on testing whether receiving punishments at the 0.08 Blood Alcohol Content (BAC) threshold reduces future recidivism of drunk driving with a local linear regression model. The findings show that receiving punishments at the threshold reduces recidivism by up to 2.4 percentage points \footnote{The average estimated effect is 2.1 percentage points. The average estimate is calculated over models based on different bandwidths and with different kernel functions, assuming equal weights of estimates.}. Robustness test based on local second-order polynomials show that receiving punishments at the threshold reduces recidivism by up to 1.6 percentage points \footnote{The average estimated effect is 1.5 percentage points.}. These estimates are consistent with those given by models that take into account non-random heaping in the data. The findings of the present study successfully replicate the main results of Hansen (2015), which gives an estimated decrease in recidivism of up to 2 percentage points due to receiving punishments at the 0.08 BAC threshold. The success of replication demonstrates the validity of the methodology and results of the original study.

Hansen (2015) also presents related results that the present study, due to its scope and the limitation of the data available, does not replicate. As a part of the strengths of the original study, these findings either establish the robustness of the main results under different assumptions or reveal the heterogeneity of the effect of receiving punishments.

In terms of the robustness of the main results, the original study estimates regression discontinuity models using polynomials up to the third order, three types of kernel functions, and based on a series of bandwidths that extend beyond 0.05 and 0.025. The results show that the point estimates are relatively consistent, except for those given by the local second-order polynomial and those estimated based on very small bandwidths.

The heterogeneity of the effects of punishments include the effects among different populations and the effect on different types of recidivism. First of all, the original study separates analyses for drivers with and without prior drunk driving experience, in addition to running regression models on the entire population of drivers. This allows the original study to find that the effect of receiving punishments at the threshold is more pronounced among drivers with previous drunk driving experience (by about 4.6 percentage points, which is 25.2 percent \footnote{The estimate of percentage points is calculated by taking the mean over the two estimates reported in Table 3 of Hansen (2015).}). Moreover, the study conducts sensitivity analyses using different measures of prior drunk driving experiences, including whether a driver has taken BAC tests, whether a driver has a previous BAC over 0.08 (and is considered a case of DUI), as well as whether a driver has a prior conviction. Across all measures, regression models give point estimates and confidence intervals that are largely similar to each other. This demonstrates the robustness of the differential effects of receiving punishments at the threshold on different populations of drivers. Second, the original study conducts a detailed analyses of the effect of receiving punishments on three types of recidivism, refusal of taking a BAC test, and the likelihood of being stopped by a police. It finds that receiving punishments decreases the likelihood of being stopped as well as recidivism of all kinds. The effect is the largest on recidivism in which a driver has a BAC values in $[0.08, 0.15]$.

Despite multiple strengths of the original study, it can still be improved in several aspects. First, although sensitivity analyses using different bandwidths in the original study establish the robustness of the results, bandwidths of 0.05 and 0.025 still seem to be arbitrary choices of the researcher. Bandwidth choice can be improved by using data-driven methods with a chosen principle. For example, Mean Squared Error (MSE) optimal bandwidth choice method is available and has been recently improved with a bias correction of point estimate for better inference [@imbens_optimal_2012, @cattaneo_choice_2017]. Alternatively, when the goal is to construct optimal confidence intervals for inference, one can choose to use a bandwidth selection method that minimises coverage error (CE) probability [@calonico_coverage_2022]. Both MSE-optimal and CE-optimal bandwidths are based on the data and constructed according to an explicit desideratum, which makes the bandwidth choice more objective and transparent. Future research can and should make full use of these methods as they are readily available in packages of major statistical software [@calonico_rdrobust_2015, @calonico_rdrobust_2017].

Second, in light of the present study, local second-order polynomials consistently give lower estimates than linear models. In fact, this is also the finding from the robustness test of the original study (Appendix Table 5 of Hansen, 2015). This suggests that the estimates of the effect of receiving punishments at the threshold are somewhat dependent on the assumptions of the effect's functional form. Although it is difficult to pin down one reasonable functional assumption due to the complex nature of the effect of punishments, future research should give equal weights in presenting the results given by different models. This is especially important for such an estimand as the effect of punishments on repeat drunk driving that is closely associated with policy making, since even a small difference in the estimate can lead to big differences when scaled up.

Third, the use of linear models is undesirable when recidivism, the outcome variable, is a binary variable. In simple words, this is because a mathematical inconsistency exists between the estimand (which can only take the value of 0 and 1) and the potential outcome of a linear model (which can take the value of any real number). In practice, future research can utilise logistic regressions in combination with regression discontinuity design to estimate the effect of punishments on recidivism. This should not be a difficult task because recent research in econometrics has developed and programmed such methods based on the multinomial logit model, together with optimal bandwidth selection and bias correction techniques [@xu_regression_2017].

Fourth, the robustness checks using donut hole regression discontinuity models are limited considering the possible non-random heaping in the data. The original study used donut hole models primarily to deal with potential confounders, but non-random heaping might also exist in light of the present study. Although the original study runs the model with observations dropped within windows of different sizes and found relatively consistent results, this method could still give biased estimates if non-random heaping outside the windows was biasing the estimation [@barreca_heaping-induced_2016]. Future studies can adopt a potential solution suggested by previous research, that is, to separate the analyses for non-heaped data and heap points (if any). Unbiased estimates can be derived by taking a population-weighted average of the two estimates based on the restricted sample sizes [@barreca_heaping-induced_2016].

Finally, the external and internal validity of the study can be improved in future extensions. To improve the external validity of the estimation, one can use data from regions other than the state of Washington. This is to establish that punishments are universally effective in reducing repeat drunk driving across regions and the effect is not caused by some other factors specific to the state of Washington. The internal validity of the causal relation can be improved by conducting a longitudinal field experiment. One can choose a region where laws criminalizing DUI are not yet enforced, and carry out an experiment by manipulating the magnitude of the punishments drivers will receive if found driving under the influence. Drivers with a BAC level just below a chosen threshold are randomly assigned to receive lighter punishments than those with a BAC level just above the threshold. This method can theoretically provide stronger evidence for the causal relation between receiving punishments and recidivism. However, there are also challenges to such designs. For example, methodologically speaking, it is hard to prevent spillover effect. Drivers may find out punishments vary among individuals, and the consequence of such an effect is essentially unpredictable. Ethically speaking, it also requires debate on how such an experiment adhere to the principle of transparency. Due to the scope of this paper, I will not expand further on these topics and will leave them to be addressed by future research.


# Conclusion

The present study successfully replicates the main results of the study *Punishment and Deterrence: Evidence from Drunk Driving* [@hansen_punishment_2015] about the effect of punishments and sanctions on reducing repeat drunk driving using a regression discontinuity design. Specifically, I find that receiving punishments at the 0.08 BAC threshold reduces recidivism by up to 2.4 percentage points according to local linear regression models, and the decrease is up to 1.6 percentage points according to local second-order polynomials. These results provide evidence for the validity of the original study. The original study also goes beyond these estimates and reveals heterogeneity of the effects. Despite these strengths, the study can still be improved in aspects such as bandwidth selection, the selection of appropriate models and robustness checks, the presentation of the results, as well as internal and external validity.

\newpage

# Appendix {-}

This appendix presents the code associated with the assignment questions. A full list of analysis code is stored in the Github repository: [https://github.com/ellen-ying/PB4A7_QuantitativeApplications](https://github.com/ellen-ying/PB4A7_QuantitativeApplications).

1. Create the variables for Driving Under the Influence, and quadratic term for Blood alcohol level and produce two histograms of BAC1 (one as a discrete variable, one as a continuous). Explain the differences of the histograms.

```{r, message=FALSE, warning=FALSE, fig.show='hide', results='hide'}
# load libraries
library(tidyverse);library(haven);library(here)
library(rdrobust);library(wesanderson)

# input data
bac_data <- 
  here("summative/data/hansen_dwi.dta") %>% # locate the data
  read_dta() %>% # read the dta file
  # code variables
  mutate(
    # code into drive under influence (dui) = 1 if bac1 >= 0.08
    dui = ifelse(bac1 >= 0.08, 1, 0), 
    # create a centered bac1 variable
    bac1_ctd = bac1 - 0.08,
    # create a quadratic term for both bac1 and bac1_ctd
    bac1_sq = bac1^2,
    bac1_ctd_sq = bac1_ctd^2,
    # create donut hole for later use
    donut = ifelse(abs(bac1_ctd) <= 0.001, 1, 0)
    )

# create the histogram treating BAC as a discrete variable
# equivalent to stata function histogram bac1, discrete width(0.001)
bac_data %>% 
  ggplot(aes(x = bac1)) +
  geom_histogram(binwidth = 0.001, fill = "grey60", color = NA) + 
  geom_vline(xintercept = 0.08, size = 0.3) +
  geom_vline(xintercept = 0.15, size = 0.3) +
  scale_x_continuous(breaks = seq(0, 0.5, by = 0.1), 
                     labels = c("0", "0.1", "0.2", "0.3", "0.4", "0.5"),
                     expand = c(0, 0.01)) +
  scale_y_continuous(breaks = seq(0, 2000, by = 500),
                     labels = c("0", "500", "1,000", "1,500", "2,000"),
                     limits = c(0, 2050),
                     expand = c(0, 0)) +
  labs(x = "Blood Alcohol Content (BAC)", y = "Frequency") +
  theme_classic() +
  theme(
    panel.grid = element_blank(),
    panel.grid.major.y = element_line(color = "grey80", size = 0.4),
    axis.line = element_line(size = 0.4),
    axis.text.y = element_text(size = 11, margin = margin(0, 5, 0, 0)),
    axis.text.x = element_text(size = 11, margin = margin(5, 0, 0, 0)),
    axis.ticks = element_line(size = 0.4),
    axis.ticks.length = unit(6, units = "pt"),
    axis.title.y = element_text(size = 13, margin = margin(0, 10, 0, 0)),
    axis.title.x = element_text(size = 13, margin = margin(10, 0, 0, 0)),
    plot.margin = margin(20, 20, 20, 20)
    
  )

# create the histogram treating BAC as a continuous variable
# equivalent to stata function histogram bac1, width(0.001)
bac_data %>% 
  mutate(bac1 = bac1 - 0.0005) %>% 
  ggplot(aes(x = bac1)) +
  geom_histogram(binwidth = 0.001, fill = "grey60", color = NA) +
  geom_vline(xintercept = 0.08 - 0.0005, size = 0.3) +
  geom_vline(xintercept = 0.15 - 0.0005, size = 0.3) +
  scale_x_continuous(breaks = seq(0, 0.5, by = 0.1), 
                     labels = c("0", "0.1", "0.2", "0.3", "0.4", "0.5"),
                     expand = c(0, 0.01)) +
  scale_y_continuous(breaks = seq(0, 3000, by = 1000),
                     labels = c("0", "1,000", "2,000", "3,000"),
                     limits = c(0, 3700),
                     expand = c(0, 0)) +
  labs(x = "Blood Alcohol Content (BAC)", y = "Frequency") +
  theme_classic() +
  theme(
    panel.grid = element_blank(),
    panel.grid.major.y = element_line(color = "grey80", size = 0.4),
    axis.line = element_line(size = 0.4),
    axis.text.y = element_text(size = 11, margin = margin(0, 5, 0, 0)),
    axis.text.x = element_text(size = 11, margin = margin(5, 0, 0, 0)),
    axis.ticks = element_line(size = 0.4),
    axis.ticks.length = unit(6, units = "pt"),
    axis.title.y = element_text(size = 13, margin = margin(0, 10, 0, 0)),
    axis.title.x = element_text(size = 13, margin = margin(10, 0, 0, 0)),
    plot.margin = margin(20, 20, 20, 20)
    
  )

```


2.	Running regressions on covariates (white, male, age and accident) to see if there is a jump in average values for each of these at the cutoff and explain the results.

```{r, message=FALSE, warning=FALSE, fig.show='hide', results='hide'}
# load the function to display summary statistics with robust standard errors
source(here("summative/code/summaryR.R"))

# get the data within the bandwidth
dat_bandwidth_0.05 <- bac_data %>% filter(abs(bac1_ctd) <= 0.05)

# check being white
white_rdd <- dat_bandwidth_0.05 %>% lm(white ~ dui*bac1_ctd, data = .)
# display results with robust SEs
summaryR.lm(white_rdd, type = "hc1") 

# check being male
male_rdd <- dat_bandwidth_0.05 %>% lm(male ~ dui*bac1_ctd, data = .)
summaryR.lm(male_rdd, type = "hc1") 

# check accident
accident_rdd <- dat_bandwidth_0.05 %>% lm(acc ~ dui*bac1_ctd, data = .)
summaryR.lm(accident_rdd, type = "hc1") 

# check age
age_rdd <- dat_bandwidth_0.05 %>% lm(aged ~ dui*bac1_ctd, data = .)
summaryR.lm(age_rdd, type = "hc1") 
```

3.	Produce main recidivism results of the paper (with our dataset) using recidivism as dependent variable as well as with a changed bandwith of the RDD to 0.055 to 0.105.

```{r, message=FALSE, warning=FALSE, fig.show='hide', results='hide'}
# linear regression
linear_a <- 
  dat_bandwidth_0.05 %>% 
  lm(recidivism ~ dui*bac1_ctd + white + male + acc + aged,
     data = .)
summaryR.lm(linear_a, type = "hc1")

# quadratic model
qua_a <- 
  dat_bandwidth_0.05 %>% 
  lm(recidivism ~ dui*(bac1_ctd + bac1_ctd_sq) + white + male + acc + aged,
     data = .)
summaryR.lm(qua_a, type = "hc1")


# get the data within the 0.025 bandwidth
dat_bandwidth_0.025 <- bac_data %>% filter(abs(bac1_ctd) <= 0.025)

# linear regression
linear_b <- 
  dat_bandwidth_0.025 %>% 
  lm(recidivism ~ dui*bac1_ctd + white + male + acc + aged,
     data = .)
summaryR.lm(linear_b, type = "hc1")

# quadratic model
qua_b <- 
  dat_bandwidth_0.025 %>% 
  lm(recidivism ~ dui*(bac1_ctd + bac1_ctd_sq) + white + male + acc + aged,
     data = .)
summaryR.lm(qua_b, type = "hc1")
```

4.	Replicate Qe by running "donut hole regressions".  Explain why one might need a donut hole regression? How do I run a donut hole regression? 
5.	Run local polynomials and explain why local polynomials might be needed after a donut hole.

```{r, message=FALSE, warning=FALSE, fig.show='hide', results='hide'}
# linear regression
linear_a_donut <- 
  dat_bandwidth_0.05 %>% 
  filter(donut == 0) %>% 
  lm(recidivism ~ dui*bac1_ctd + white + male + acc + aged,
     data = .)
summaryR.lm(linear_a_donut, type = "hc1")

# narrower bandwidth
linear_b_donut <- 
  dat_bandwidth_0.025 %>% 
  filter(donut == 0) %>% 
  lm(recidivism ~ dui*bac1_ctd + white + male + acc + aged,
     data = .)
summaryR.lm(linear_b_donut, type = "hc1")

# quadratic model
qua_a_donut <- 
  dat_bandwidth_0.05 %>% 
  filter(donut == 0) %>% 
  lm(recidivism ~ dui*(bac1_ctd + bac1_ctd_sq) + white + male + acc + aged,
     data = .)
summaryR.lm(qua_a_donut, type = "hc1")

# narrower bandwidth
qua_b_donut <- 
  dat_bandwidth_0.025 %>% 
  filter(donut == 0) %>% 
  lm(recidivism ~ dui*(bac1_ctd + bac1_ctd_sq) + white + male + acc + aged,
     data = .)
summaryR.lm(qua_b_donut, type = "hc1")
```

6.	Produce an RDplot and a cmogram with bandwidths of 0.060 & 0.11. Explain what the respective graphs show.

```{r, message=FALSE, warning=FALSE, fig.show='hide', results='hide'}
# replicate the cmogram output given by stata
# get the trimmed data
dat_tirmmed <- bac_data %>% filter(bac1 > 0.06 & bac1 < 0.11)

# number of breaks left to the cutoff
n_left <- 
  filter(dat_tirmmed, bac1_ctd < 0) %>% 
  nrow() %>% 
  min(sqrt(.), 10*log(.)/log(10)) %>% 
  floor() + 1
# number of breaks right to the cutoff
n_right <- 
  filter(dat_tirmmed, bac1_ctd >= 0) %>% 
  nrow() %>% 
  min(sqrt(.), 10*log(.)/log(10)) %>% 
  floor() + 1

# get the breaks based on bin numbers
min_bac <- min(dat_tirmmed$bac1)
max_bac_lower <- filter(dat_tirmmed, bac1_ctd < 0)$bac1 %>% max()
max_bac <- max(dat_tirmmed$bac1) 
breaks <- c(seq(min_bac, max_bac_lower, length.out = n_left), 
               seq(0.08, max_bac, length.out = n_right))

# plotting
dat_tirmmed %>% 
  # create the bins
  mutate(bins = cut(bac1, breaks = breaks)) %>% 
  group_by(bins) %>% 
  summarize(
    recidivism = mean(recidivism), # calculate the mean recidivism in each group
    bac = mean(bac1), # roughly the midpoint of each bin for plotting the x axis
    dui = ifelse(bac >=0.08, 1, 0) %>% factor() # indicator for DUI
  ) %>% 
  ggplot(aes(x = bac, y = recidivism, color = dui)) +
  geom_point(show.legend = FALSE) +
  # superimpose a fitted line model and confidence interval using the raw data
  geom_smooth(data = dat_tirmmed,
              aes(x = bac1, y = recidivism, color = dui),
              method = "lm", formula = y ~ x,
              inherit.aes = FALSE, show.legend = FALSE) +
  # # a quadratic model with CI
  # geom_smooth(data = dat_tirmmed,
  #             aes(x = bac1, y = recidivism, color = dui),
  #             method = "lm", formula = y ~ poly(x, 2),
  #             inherit.aes = FALSE, show.legend = FALSE) +
  geom_vline(xintercept = 0.08, color = "red", linetype = 2) +
  scale_x_continuous(breaks = seq(0.02, 0.14, by = 0.02)) +
  scale_y_continuous(breaks = seq(0.07, 0.15, by = 0.02)) +
  scale_color_discrete(type = wes_palette("Royal1", 2, type = "discrete")) +
  labs(x = "Blood Alcohol Content (BAC)", y = "Recidivism") +
  theme_classic() +
  theme(
    panel.grid = element_blank(),
    panel.grid.major.y = element_line(color = "grey80", size = 0.4),
    axis.line = element_line(size = 0.4),
    axis.text.y = element_text(size = 11, margin = margin(0, 5, 0, 0)),
    axis.text.x = element_text(size = 11, margin = margin(5, 0, 0, 0)),
    axis.ticks = element_line(size = 0.4),
    axis.ticks.length = unit(6, units = "pt"),
    axis.title.y = element_text(size = 13, margin = margin(0, 10, 0, 0)),
    axis.title.x = element_text(size = 13, margin = margin(10, 0, 0, 0)),
    plot.margin = margin(20, 20, 20, 20)
  )


# RD plot
# run the rdrobust model
rd <- with(dat_tirmmed,
     rdplot(recidivism, bac1,
            c = 0.08, # cutoff point
            p = 1, # order of the polynomial
            binselect = "qs", # method for select number of bins
            masspoints = FALSE,
            ci = 95,
            hide = TRUE)
     )

# get the statistics for plotting
c = 0.08 # threshold
rdplot_mean_bin = rd$vars_bins[,"rdplot_mean_bin"]
rdplot_mean_y   = rd$vars_bins[,"rdplot_mean_y"]
y_hat           = rd$vars_poly[,"rdplot_y"]
x_plot          = rd$vars_poly[,"rdplot_x"]
rdplot_cil_bin =  rd$vars_bins[,"rdplot_ci_l"]
rdplot_cir_bin =  rd$vars_bins[,"rdplot_ci_r"]
rdplot_mean_bin=  rd$vars_bins[,"rdplot_mean_bin"]
y_hat_r=y_hat[x_plot>=c][-1]
y_hat_l=y_hat[x_plot<c]
x_plot_r=x_plot[x_plot>=c][-1]
x_plot_l=x_plot[x_plot<c]
# collect dots for plotting lines in one tibble
line <- tibble(x = c(x_plot_l, x_plot_r),
       y = c(y_hat_l, y_hat_r),
       dui = c(rep(0, 499), rep(1, 500)) %>% factor()) 

# plotting
ggplot() + 
  geom_point(aes(x = rdplot_mean_bin, y = rdplot_mean_y), 
            col = "#728C94", na.rm = TRUE) +
  geom_line(data = line, aes(x = x, y = y, color = dui), 
            na.rm = TRUE, inherit.aes = FALSE, show.legend = FALSE) +
  geom_ribbon(aes(x = rdplot_mean_bin, ymin = rdplot_cil_bin, ymax = rdplot_cir_bin),
              fill = "#CE0000", alpha = 0.2) +
  scale_x_continuous(breaks = seq(0.06, 0.11, by = 0.01), expand = c(0.03, 0)) +
  scale_y_continuous(breaks = seq(0.07, 0.17, by = 0.02)) +
  scale_color_discrete(type = c("#CE0000", "#CE0000")) +
  labs(x = "Blood Alcohol Content (BAC)", y = "Recidivism") +
  geom_vline(xintercept = 0.08, size = 0.3, linetype = 2) +
  theme_classic() +
  theme(
    panel.grid = element_blank(),
    panel.grid.major.y = element_line(color = "grey80", size = 0.4),
    axis.line = element_line(size = 0.4),
    axis.text.y = element_text(size = 11, margin = margin(0, 5, 0, 0)),
    axis.text.x = element_text(size = 11, margin = margin(5, 0, 0, 0)),
    axis.ticks = element_line(size = 0.4),
    axis.ticks.length = unit(6, units = "pt"),
    axis.title.y = element_text(size = 13, margin = margin(0, 10, 0, 0)),
    axis.title.x = element_text(size = 13, margin = margin(10, 0, 0, 0)),
    plot.margin = margin(20, 20, 20, 20)
  )
```

\newpage

# References{-}

<div id="refs"></div>
